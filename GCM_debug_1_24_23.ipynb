{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a95ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sat Sep 03 2022\n",
    "@author: Emily Remirez (eremirez@berkeley.edu)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb36790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions for implementing the Generalized Context Model for speech perception.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a70a32",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(testset, cloud, dimsdict, c = 25):\n",
    "    '''\n",
    "    Calculate activation for all exemplars stored in the cloud\n",
    "    with respect to some stimulus, referred to as test. Returns\n",
    "    a data frame with column 'a' added for each row.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one or more rows, each a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "    \n",
    "    dimsdict = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to 25. \n",
    "        \n",
    "    '''\n",
    "    # Get stuff ready\n",
    "    dims = dimsdict.copy()\n",
    "    dims.update((x, (y/sum(dims.values()))) for x, y in dims.items())   # Normalize weights to sum to 1\n",
    "    \n",
    "    # If the testset happens to have N in it, remove it before joining dfs \n",
    "    test = testset.copy()\n",
    "    if 'N' in test.columns:\n",
    "        test = test.drop(columns='N', axis=1,inplace=True)\n",
    "    \n",
    "    exemplars = cloud.copy()\n",
    "\n",
    "    # Merge test and exemplars\n",
    "    bigdf = pd.merge(\n",
    "        test.assign(key = 1),         # Add column named 'key' with all values == 1\n",
    "        exemplars.assign(key = 1),    # Add column named 'key' with all values == 1\n",
    "        on = 'key',                   # Match on 'key' to get cross join (cartesian product)\n",
    "        suffixes = ['_t', '_ex']\n",
    "    ).drop('key', axis=1)           # Drop 'key' column\n",
    "    \n",
    "    \n",
    "    dimensions = list(dims.keys())                # Get dimensions from dictionary\n",
    "    weights = list(dims.values())                 # Get weights from dictionary\n",
    "    tcols = [f'{d}_t' for d in dimensions]      # Get names of all test columns\n",
    "    excols = [f'{d}_ex' for d in dimensions]    # Get names of all exemplar columns\n",
    "    \n",
    "    \n",
    "    # Multiply each dimension by weights\n",
    "    i = bigdf.loc[:, tcols].values.astype(float)     # Get all the test columns\n",
    "    i *= weights                                     # Multiply test columns by weight\n",
    "    j = bigdf.loc[:, excols].values.astype(float)    # Get all the exemplar columns\n",
    "    j *= weights                                     # Multiply exemplar columns by weights\n",
    "    \n",
    "    # Get Euclidean distance\n",
    "    bigdf['dist'] = np.sqrt(np.sum((i-j)**2, axis=1))\n",
    "    \n",
    "    # get activation: exponent of negative distance * sensitivity c, multiplied by N_j\n",
    "    bigdf['a'] = np.exp(-bigdf.dist*c) * bigdf.N\n",
    "    return bigdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(cloud, test, exclude_self = True, alsoexclude = None): \n",
    "    '''\n",
    "    Removes specific rows from the cloud of exemplars, to be used\n",
    "    prior to calculating activation. Prevents activation from being\n",
    "    overpowered by stimuli that are too similar to particular exemplars.\n",
    "    E.g., prevents comparison of a stimulus to itself, or to exemplars from same speaker\n",
    "    Returns dataframe containing a subset of rows from the cloud.\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar\n",
    "    \n",
    "    test = single row dataframe containing the stimulus to be categorized\n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "    \n",
    "    Optional parameters:\n",
    "    \n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    '''\n",
    "    # Make a copy of the cloud and call it exemplars. \n",
    "    #    This is what we'll return at the end\n",
    "    exemplars = cloud.copy()\n",
    "    \n",
    "    # Remove the stimulus from the cloud\n",
    "    if exclude_self == True:\n",
    "        exemplars = exemplars[~exemplars.isin(test)].dropna()  \n",
    "    \n",
    "    if alsoexclude != None:\n",
    "        for feature in alsoexclude:\n",
    "            featval = test[feature].iloc[0]\n",
    "            exclude_exemps = exemplars[exemplars[feature] == featval].index\n",
    "            exemplars = exemplars.drop(exclude_exemps, inplace = True)\n",
    "    return exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43325b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_N(exemplars, N = 1):\n",
    "    '''\n",
    "    Adds an N (base activation) column to the exemplar cloud so\n",
    "    that activation with respect to the stimulus can be calculated\n",
    "    Default value is 1, i.e., equal activation for each exemplar.\n",
    "    Returns the exemplar data frame with added or reset column\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    exemplars = data frame of exemplars to which the stimulus is being\n",
    "        compared\n",
    "        \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1\n",
    "    '''\n",
    "    extemp = exemplars.copy()\n",
    "    extemp['N'] = N\n",
    "    return extemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a429da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_N(exemplars, cat, catbias):\n",
    "    '''\n",
    "    Adds or overwrites an N (base activation) colummn to the exemplar \n",
    "    cloud so that activation with respect to the stimulus can be \n",
    "    calculated. Unlike reset_N, which assigns the same N value to all exemplars,\n",
    "    bias_N will set N values according to values in a dictionary. That is, within a \n",
    "    category type, each category will have the N value specified in the dictionary\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    exemplars = dataframe of exemplars to which the stimulus is being compared\n",
    "    \n",
    "    cat = a string designating the category type which is being primed\n",
    "    \n",
    "    catbias = dictionary with categories (e.g. vowels) as keys and N value for the  \n",
    "        category as values\n",
    "    '''\n",
    "    extemp = exemplars.copy()\n",
    "    extemp['N'] = extemp[cat].map(catbias)\n",
    "    return extemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs(bigdf, cats):    \n",
    "    '''\n",
    "    Calculates the probability that the stimulus will be categorized with a\n",
    "    particular label for a given category (e.g., vowel labels 'i', 'a', 'u' for\n",
    "    the category 'vowel'). Probability is calculated by summing the activation\n",
    "    across all exemplars sharing a label, and dividing that by the total amount\n",
    "    of activation in the system for the category. Returns a dictionary of dictionaries.\n",
    "    Each key is a category; values are dictionaries where keys are labels and values\n",
    "    represent probability of the stimulus being categorized into that label.\n",
    "    \n",
    "    Required parameters: \n",
    "    \n",
    "    bigdf = a dataframe produced by activation(), which contains a row for each\n",
    "        exemplar with the additional column 'a' representing the amount of \n",
    "        activation for that exemplar with respect to the stimulus\n",
    "    \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    '''\n",
    "    prs = {}\n",
    "    \n",
    "    if type(cats) != list:\n",
    "        cats = [cats]\n",
    "    \n",
    "    # Loop over every category in the list of categories\n",
    "    for cat in cats: \n",
    "        if cat in bigdf:\n",
    "            label = cat\n",
    "        else: \n",
    "            # make category match the exemplar category in name if i and j share column names\n",
    "            label = cat + '_ex'\n",
    "            \n",
    "        # Sum up activation for every label within that category\n",
    "        cat_a = bigdf.groupby(label).a.sum()\n",
    "        # Divide the activation for each label by the total activation for that category\n",
    "        pr = cat_a / sum(cat_a)\n",
    "        # rename a for activation to probability\n",
    "        pr = pr.rename_axis(cat).reset_index().rename(columns={\"a\" : \"probability\"})\n",
    "        # add this to the dictionary \n",
    "        prs[cat] = pr\n",
    "    return prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a50497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(probsdict, test, cats, runnerup = False, fc = None):\n",
    "    '''\n",
    "    Chooses a label for each category which the stimulus will be categorized as.\n",
    "    Returns the test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability. Optionally will give the\n",
    "    second most probable label as well. \n",
    "    \n",
    "    Required parameters:\n",
    "    pr = dictionary of probabilities, given from probs(). Each key should represent\n",
    "        a category (e.g. 'vowel'), with values as dataframe. Dataframe should\n",
    "        have a probability for each category label\n",
    "        \n",
    "    test = single line data frame representing the test/stimulus being categorized\n",
    "    \n",
    "    cats = list of categories to be considered (e.g., [\"vowel\"])\n",
    "            \n",
    "    Optional parameters:\n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False. \n",
    "        \n",
    "    fc = Dict where keys are category names in the dataframe and values are a list of category labels.\n",
    "        Used to simulate a forced choice experiment in which the perceiver has a limited number\n",
    "        of alternatives. For example, if fc = {'vowel':['i','a']}, the choice will be the alternative \n",
    "        with higher probability, regardless of whether other vowels not listed have higher probabilities. \n",
    "        There can be any number of alternatives in the list.\n",
    "    \n",
    "    '''\n",
    "    newtest = test.copy()      # make a copy of the test set to add to\n",
    "    pr = probsdict.copy()        # make a copy of the probs dict to subset if forced choice is set\n",
    "    print(pr)\n",
    "    print('hewwo3')\n",
    "    choice = ''\n",
    "    choiceprob = 1\n",
    "    \n",
    "    # If using forced choice, restrict the choices to the terms \n",
    "    # This doesn't change the probability! So something could have a low prob,\n",
    "    ## but still be the winner\n",
    "    if fc != None: \n",
    "        fccats = fc.keys()\n",
    "        for fccat in fccats:\n",
    "            options = fc[fccat]\n",
    "            scope = probsdict[fccat]\n",
    "            toconsider = scope.loc[scope[fccat].isin(options)]\n",
    "        pr[fccat] = toconsider\n",
    "\n",
    "    for cat in cats:\n",
    "        choicename = cat + 'Choice'\n",
    "        choiceprobname = cat + 'Prob'\n",
    "        \n",
    "        dframe = pr[cat]\n",
    "        print(dframe)\n",
    "        print('testing_hewwo')\n",
    "        prob = dframe['probability']\n",
    "        print(prob)\n",
    "        print('hewwo')\n",
    "        winner = dframe.loc[prob==max(prob)]\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "        # if more than one winner, choose randomly\n",
    "        if len(winner) > 1:\n",
    "            winner = winner.sample(1)\n",
    "            \n",
    "        print(type(winner))\n",
    "        print(winner)\n",
    "        \n",
    "        choice = winner[cat].item()\n",
    "        choiceprob = winner['probability'].item()\n",
    "        \n",
    "        newtest[choicename] = choice\n",
    "        newtest[choiceprobname] = choiceprob      \n",
    "    return newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f48b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(testset, cloud, cats, dimsdict, c, \n",
    "               exclude_self = True, alsoexclude = None, N=1, runnerup=False, fc=None):\n",
    "    '''\n",
    "    Categorizes a stimulus based on functions defined in library. \n",
    "    1. Exclude any desired stimuli\n",
    "    2. Add N value\n",
    "    3. Calculate activation\n",
    "    4. Calculate probabilities\n",
    "    5. Choose labels for each category\n",
    "    Returns the output of choose(): test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one row, a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "        \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "    \n",
    "    dimsdict = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to .01. \n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "        \n",
    "    Optional parameters:\n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1\n",
    "        \n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False.\n",
    "\n",
    "    '''\n",
    "    exemplars = cloud.copy()\n",
    "    test = testset\n",
    "    exemplars = exclude(exemplars, test, exclude_self = exclude_self, alsoexclude = alsoexclude)\n",
    "    exemplars = reset_N(exemplars, N = N)\n",
    "    bigdf = activation(test, exemplars, dimsdict = dimsdict, c = c)\n",
    "    pr = probs(bigdf, cats)\n",
    "    choices = choose(pr, test, cats, runnerup = runnerup, fc = fc)\n",
    "    return choices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab430b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def multicat(testset, cloud, cats, dimsdict, c = 25, N = 1, biascat = None, catbias = None, rescat = None, ncyc = None,\n",
    "                 exclude_self = True, alsoexclude = None, runnerup = False, fc = None):\n",
    "    '''\n",
    "    Categorizes a dataframe of 1 or more stimuli based on functions defined in library\n",
    "    \n",
    "    1. Exclude any desired stimuli\n",
    "    2. Add N value\n",
    "    3. Calculate activation\n",
    "    4. Calculate probabilities\n",
    "    5. Choose labels for each category\n",
    "    Returns the output of choose(): test/stimulus dataframe with added columns showing what was \n",
    "    chosen for a category and with what probability\n",
    "    \n",
    "    Required parameters:\n",
    "    \n",
    "    testset = a dataframe with one or more rows, each a stimulus to be categorized\n",
    "        must have columns matching those given in the 'dims' dict. These columns\n",
    "        should be dimensions of the stimulus (e.g., formants)\n",
    "        \n",
    "    cloud = A dataframe of stored exemplars which every stimulus is compared to. \n",
    "        Each row is an exemplar, which, like testset should have columns matching\n",
    "        those in the dims dict\n",
    "        \n",
    "    cats = a list of strings containing at least one item, indicating which\n",
    "        categories probability should be calculated for (e.g. ['vowel','gender']).\n",
    "        Items should match the name of columns in the data frame\n",
    "        \n",
    "    dimsdict = a dictionary with dimensions as keys and weights, w, as values. \n",
    "    \n",
    "    c = an integer representing exemplar sensitivity. Defaults to 25. \n",
    "    \n",
    "    exclude_self = boolean. If True, stimulus will be removed from exemplar cloud\n",
    "        so that it isn't compared to itself. Defaults to True \n",
    "        \n",
    "    Optional parameters:\n",
    "    \n",
    "    biascat = A string indicating the category type to be biased or primed on (e.g. 'vowel', 'speaker')\n",
    "    \n",
    "    catbias = Dict where keys are categories of biascat and values are\n",
    "        ints that indicate relative N values. (e.g., {'i':5,'a':1} would make every 'i' exemplar \n",
    "        contribute 5 times as much activation as each 'a)\n",
    "    \n",
    "    rescat = Category to resonate on. If given, \n",
    "    \n",
    "    ncyc = Int indicating how many cycles of resonance\n",
    "    \n",
    "    alsoexclude = a list of strings matching columns in the cloud (categories) to exclude \n",
    "        if value is the same as that of the test. (E.g., to exclude all exemplars from\n",
    "        the speaker to simulate categorization of novel speaker)\n",
    "    \n",
    "    N = integer indicating the base activation value to be added to\n",
    "        each exemplar (row) in the dataframe. Defaults to 1\n",
    "        \n",
    "    runnerup = boolean; when true the label with the second highest probability\n",
    "        will also be included in the dataframe. Defaults to False.\n",
    "        \n",
    "    fc = Dict where keys are category names in the dataframe and values are a list of category labels.\n",
    "        Used to simulate a forced choice experiment in which the perceiver has a limited number\n",
    "        of alternatives. For example, if fc = {'vowel':['i','a']}, the choice will be the alternative \n",
    "        with higher probability, regardless of whether other vowels not listed have higher probabilities. \n",
    "        There can be any number of alternatives in the list. \n",
    "    '''\n",
    "    choicelist=[]\n",
    "    for ix in list(testset.index.values):\n",
    "        # Reload exemplars within the loop\n",
    "        ## if not, exemplars shrinks every time you use exclude()!\n",
    "        exemplars = cloud.copy()   \n",
    "        test = testset.loc[[ix,]]\n",
    "        \n",
    "        # exclusions\n",
    "        exemplars = exclude(exemplars, test, exclude_self = exclude_self, alsoexclude = alsoexclude)\n",
    "        \n",
    "        #add N \n",
    "        if catbias != None: \n",
    "            exemplars = bias_N(exemplars, biascat, catbias)\n",
    "        else: exemplars = reset_N(exemplars, N = N)\n",
    "        \n",
    "        # calculate probabilities\n",
    "        bigdf = activation(test, exemplars, dimsdict = dimsdict, c = c)\n",
    "        pr = probs(bigdf, cats)\n",
    "        \n",
    "        # resonate if applicable -- recalculate probs based on a resonance term\n",
    "        if rescat != None:\n",
    "            for n in range(0, ncyc):\n",
    "                edict = pr[rescat].set_index(rescat).to_dict()['probability']\n",
    "                # resonance term = probability of category divided by number of cycles\n",
    "                    ## so that effect decays over time\n",
    "                exemplars['resterm'] = exemplars[rescat].map(edict) / (n+1)\n",
    "                # Add resterm to N value; N only ever goes up\n",
    "                exemplars['N'] = exemplars['N'] + exemplars['resterm']\n",
    "                bigdf = activation(test, exemplars, dimsdict = dimsdict, c = c)\n",
    "                pr = probs(bigdf, cats)\n",
    "        \n",
    "        # Luce's choice rule\n",
    "        choicerow = choose(pr, test, cats, runnerup = runnerup, fc = fc)       \n",
    "        choicelist.append(choicerow)\n",
    "        \n",
    "    choices = pd.concat(choicelist, ignore_index = True)\n",
    "    return choices"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
